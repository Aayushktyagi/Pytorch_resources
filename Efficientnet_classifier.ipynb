{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Efficientnet_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNec/ehQKEQJ0w9Wkon+TF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayushktyagi/Pytorch_resources/blob/master/Efficientnet_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpxTSIfIlz-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FphVxiXD-qcl",
        "colab_type": "text"
      },
      "source": [
        "# Stanford Dog classification \n",
        "\n",
        "*   Loading dataset \n",
        "  1.   wget images\n",
        "  2.   unzip\n",
        "  3.   resize to 256x256\n",
        "\n",
        "\n",
        "*   Dataset Visualization\n",
        "*   Initialize EfficientNet\n",
        "*   Train EfficientNet\n",
        "*   Evaluate model \n",
        "*   Visualize predictions \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLlPviRDA2Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os import path"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Kirjbmo32r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load dataset\n",
        "if os.path.exists(\"images.tar\") and os.path.exists(\"annotation.tar\"):\n",
        "  # unzip images and annotations \n",
        "  print(\"file exist: Unzipping ....\")\n",
        "  !tar -xvf images.tar\n",
        "  !tar -xvf annotation.tar\n",
        "else:\n",
        "  !wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
        "  !wget http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar\n",
        "  # unzip images and annotations \n",
        "  !tar -xvf images.tar\n",
        "  !tar -xvf annotation.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBgbiHjYErii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "from torchvision import models, datasets , transforms\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import Subset\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time \n",
        "import torch.nn as nn \n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R7_keyERwes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07b7750c-7a08-4fa1-ea2d-4d730f2a7902"
      },
      "source": [
        "# pre-process datasest\n",
        "\n",
        "folder_name = 'Images'\n",
        "\n",
        "data_transforms = {\n",
        "    'Train': transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize([0.485, 0.456, 406],[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'Test': transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "  def __init__(self, dataset, transform = None):\n",
        "    self.dataset = dataset\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    if self.transform:\n",
        "      x = self.transform(self.dataset[index][0])\n",
        "    else:\n",
        "      x = self.dataset[index][0]\n",
        "    y = self.dataset[index][1]\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "#get data instance\n",
        "imagedatafolder = datasets.ImageFolder(folder_name)\n",
        "traindataset = CustomDataSet(imagedatafolder , data_transforms['Train'])\n",
        "validdataset = CustomDataSet(imagedatafolder , data_transforms['Test'])\n",
        "testdataset = CustomDataSet(imagedatafolder, data_transforms['Test'])\n",
        "\n",
        "# train valid test split\n",
        "\n",
        "train_size = 0.8\n",
        "data_shuffle = True\n",
        "random_seed = 42\n",
        "batch_size = 32\n",
        "num_worker = 0\n",
        "visualizeimage = False\n",
        "save_model = False\n",
        "\n",
        "dataset_size = len(imagedatafolder)\n",
        "indices = list(range(dataset_size))\n",
        "\n",
        "split = int(np.floor(train_size * dataset_size))\n",
        "split2 = int(np.floor( (train_size + (1-train_size) / 2)* dataset_size))\n",
        "\n",
        "if data_shuffle:\n",
        "  np.random.seed(random_seed)\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "train_idx , valid_idx , test_idx = indices[:split] , indices[split:split2] , indices[split2:]\n",
        "\n",
        "trainsplit = Subset(traindataset , train_idx)\n",
        "validsplit = Subset(validdataset , valid_idx)\n",
        "testsplit = Subset(testdataset , test_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainsplit , batch_size = batch_size,\n",
        "                                          num_workers = num_worker , drop_last = True)\n",
        "validloader = torch.utils.data.DataLoader(validsplit, batch_size = batch_size,\n",
        "                                          num_workers = num_worker , drop_last= True)\n",
        "testloader = torch.utils.data.DataLoader(testsplit, batch_size = batch_size,\n",
        "                                         num_workers = num_worker, drop_last= True)\n",
        "\n",
        "# check size of train, valid, test\n",
        "\n",
        "print(\"Train:{} , Valid:{} , Test:{}\".format(len(trainloader),len(validloader),len(testloader)))\n",
        "\n",
        "use_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:514 , Valid:64 , Test:64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsNl8PWoZiYS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "acaab0a6-ed0c-4a0e-9134-05c9bf4344b9"
      },
      "source": [
        "classes  = imagedatafolder.classes\n",
        "classes_name = []\n",
        "# split name from \"-\" \n",
        "for i  in classes:\n",
        "  name = i.split(\"-\")\n",
        "  classes_name.append(name[1]) \n",
        "\n",
        "print(classes_name , len(classes_name))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Chihuahua', 'Japanese_spaniel', 'Maltese_dog', 'Pekinese', 'Shih', 'Blenheim_spaniel', 'papillon', 'toy_terrier', 'Rhodesian_ridgeback', 'Afghan_hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black', 'Walker_hound', 'English_foxhound', 'redbone', 'borzoi', 'Irish_wolfhound', 'Italian_greyhound', 'whippet', 'Ibizan_hound', 'Norwegian_elkhound', 'otterhound', 'Saluki', 'Scottish_deerhound', 'Weimaraner', 'Staffordshire_bullterrier', 'American_Staffordshire_terrier', 'Bedlington_terrier', 'Border_terrier', 'Kerry_blue_terrier', 'Irish_terrier', 'Norfolk_terrier', 'Norwich_terrier', 'Yorkshire_terrier', 'wire', 'Lakeland_terrier', 'Sealyham_terrier', 'Airedale', 'cairn', 'Australian_terrier', 'Dandie_Dinmont', 'Boston_bull', 'miniature_schnauzer', 'giant_schnauzer', 'standard_schnauzer', 'Scotch_terrier', 'Tibetan_terrier', 'silky_terrier', 'soft', 'West_Highland_white_terrier', 'Lhasa', 'flat', 'curly', 'golden_retriever', 'Labrador_retriever', 'Chesapeake_Bay_retriever', 'German_short', 'vizsla', 'English_setter', 'Irish_setter', 'Gordon_setter', 'Brittany_spaniel', 'clumber', 'English_springer', 'Welsh_springer_spaniel', 'cocker_spaniel', 'Sussex_spaniel', 'Irish_water_spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old_English_sheepdog', 'Shetland_sheepdog', 'collie', 'Border_collie', 'Bouvier_des_Flandres', 'Rottweiler', 'German_shepherd', 'Doberman', 'miniature_pinscher', 'Greater_Swiss_Mountain_dog', 'Bernese_mountain_dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull_mastiff', 'Tibetan_mastiff', 'French_bulldog', 'Great_Dane', 'Saint_Bernard', 'Eskimo_dog', 'malamute', 'Siberian_husky', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great_Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon_griffon', 'Pembroke', 'Cardigan', 'toy_poodle', 'miniature_poodle', 'standard_poodle', 'Mexican_hairless', 'dingo', 'dhole', 'African_hunting_dog'] 120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC1s1D5vld1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data visualization \n",
        "# Class histogram \n",
        "\n",
        "def imshow(img , title = None):\n",
        "  img = img.numpy().transpose((1,2,0))\n",
        "  # mean = np.array([0.485 , 0.456, 0.406])\n",
        "  # std = np.array([0.229,0.224,0.225])\n",
        "  # img = std * img + mean\n",
        "  img = np.clip(img , 0,1)\n",
        "  plt.imshow(img)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.pause(0.001)\n",
        "\n",
        "#show image \n",
        "if visualizeimage:\n",
        "  images , labels = next(iter(trainloader))\n",
        "\n",
        "  #make grid\n",
        "  out = torchvision.utils.make_grid(images)\n",
        "  \n",
        "  imshow(out , title = [classes_name[x] for x in labels])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMP1zUp6vlGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCxSJSriqKAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define efficientnet model \n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "model = EfficientNet.from_name('efficientnet-b1')\n",
        "\n",
        "#unfreez model \n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "# define linear layur to map num of classes \n",
        "num_input_features = model._fc.in_features \n",
        "model._fc = nn.Linear(num_input_features , len(classes_name))\n",
        "\n",
        "if use_gpu:\n",
        "  model = model.cuda()\n",
        "\n",
        "# print(model)\n",
        "\n",
        "#define loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define optimizer \n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01 , momentum = 0.09)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqLgdmZdSwaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion , optimizer , num_epochs = 25 , save_model = False):\n",
        "  start_time = time.time()\n",
        "\n",
        "  best_model_wts = model.state_dict()\n",
        "  best_acc = 0.0\n",
        "  total_step = len(trainloader)\n",
        "  for epochs in range(num_epochs):\n",
        "    # print(\"{}/{}\".format(epochs , num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['Training' , 'Validation']:\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      running_correct = 0\n",
        "\n",
        "      if phase == 'Training':\n",
        "        model = model.train()\n",
        "        for batch_idx , (images , labels) in enumerate(trainloader):\n",
        "          if use_gpu:\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "          else:\n",
        "            images = Variable(images)\n",
        "            labels = Variable(labels)\n",
        "          #zero the parameter gradient\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #forward\n",
        "          out = model(images)\n",
        "          _ , preds = torch.max(out.data , 1)\n",
        "          loss = criterion(out , labels)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          #stats \n",
        "          running_loss += loss.item()\n",
        "          running_correct += torch.sum(preds == labels.data)\n",
        "\n",
        "          if batch_idx % 100 == 0:\n",
        "            print(\"Epochs:{}/{} ,steps:{}/{}, loss:{} \".format(epochs , num_epochs , batch_idx , total_step , loss))\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epochs_acc = running_correct.double() / len(trainloader)\n",
        "\n",
        "        print(\"{} : Loss : {} : Acc : {}\".format(phase , epoch_loss , epochs_acc))\n",
        "      \n",
        "      if phase == 'Validation':\n",
        "        with torch.no_grad():\n",
        "          model = model.eval()\n",
        "          for images , labels in validloader:\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "            #zero the parameter gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            out = model(images)\n",
        "            _ , preds = torch.max(out.data,1)\n",
        "            loss = criterion(out, labels)\n",
        "\n",
        "            #stats\n",
        "            running_loss += loss.item()\n",
        "            running_correct += torch.sum(preds == labels.data)\n",
        "\n",
        "          epoch_loss = running_loss / len(trainloader)\n",
        "          epochs_acc = running_correct.double() / len(trainloader)\n",
        "\n",
        "          print(\"{} : Loss:{} : Acc : {}\".format(phase , epoch_loss , epochs_acc))\n",
        "\n",
        "          if epochs_acc > best_acc:\n",
        "            bast_acc = epochs_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "            if save_model:\n",
        "              state = {'model':model.state_dict() , 'optim':optimizer.state_dict()}\n",
        "              torch.save(state , 'efficientnet_dogbreed.pth')\n",
        "\n",
        "  time_escaped = time.time() - start_time\n",
        "  print(\"Training completed in :{:.0f}m {:.0f}s\".format(time_escaped // 60 , time_escaped % 60)) \n",
        "\n",
        "  print(\"Best val accuracy:{}\".format(best_acc))\n",
        "\n",
        "  #return best model \n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anTU3zGvw_Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_t = train_model(model , criterion , optimizer, num_epochs = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgUDY9d84_42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBXoEWMICgxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}